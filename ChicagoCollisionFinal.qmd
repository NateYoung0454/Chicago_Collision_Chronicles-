---
title: "Chicago Collision Report - Final"
author: "Murtaza Jawid, Kevin Norris, Yota Sugai, Nathan Young"
format: html
editor: visual
---

## STAT 627 Final Report: Chicago Collision Chronicles - A Multifaceted Statistical Analysis

## Introduction

In the city of Chicago, where the urban rhythm never sleeps, vehicular accidents occur with far too much frequency.  Each collision tells a story, of not only lives changed and families separated, but also of the many factors that intertwine in a split second to affect the outcome.  Our project aims to understand the small details of these crashes, seeking patterns amongst the chaos and insights discovered within the data.

We plan to conduct our analysis through two distinct avenues: regression and classification.  With regression, we want to uncover the underlying relationships between various factors and the financial toll of accidents.  We hope to decipher the monetary aftermath of a crash, drawing connections between factors such as posted speed limits, weather conditions, light changes, and crash types.  The information we discover can empower policymakers and safety advocates with actionable insights to reduce risks and allocate resources effectively.

At the same time, the path of classification invites us to distinguish between binary outcomes and multiple class differences.  Using the tools available with machine learning, we want to predict the fatal aftermath of a crash, discerning nuances in weather conditions, road defects and traffic control devices.  These findings could potentially inform emergency response strategies and preemptive measures, saving the lives of those who regularly engage in urban transit.  These extend beyond just drivers, and include pedestrians, cyclists, and residents of the community at large.

Our planned approach to analyzing this dataset is multifaceted, involving the framing of the problem(s), the data at our disposal, the methods we wield, and the outcomes we envision.  Through the proper setup, we encourage clarity instead of complexity when sifting through the nuances of our inquiries.  With methods ranging from regression algorithms to classification frameworks, we traverse the statistical territory in front of us.  At the end of the day, we hope to contribute to a safer, more informed urban transit landscape through the work contained herein regarding car crash analysis.

### The Data Source/Cleaning the Data

The primary data source for our analysis is the Crash Data from the City of Chicago, sourced directly from the electronic crash reporting system (E-Crash) maintained by the Chicago Police Department (CPD).  As recorded by CDP, this dataset encompasses information pertaining to every traffic crash occurring on city streets within Chicago's jurisdiction.  The dataset withholds any personally identifiable information, maintaining privacy protocols.  The dataset spans from 2017 onwards for citywide data, with some police districts having data available from 2015.  Approximately half of the crash reports are self-reported by the involved driver or drivers at the police district, while the remainder are recorded be responding police officers at the crash scene.  When analyzing the dataset, it's crucial to acknowledge potential discrepancies in recorded parameters such as street conditions, weather conditions and posted speed limits, as these are usually based on the reporting officer's assessment at the time of the incident.

Understanding the limitations of the dataset is paramount.  Not all traffic crashes within Chicago's city limits may be captured in this dataset, as crashes on interstate highways, freeway ramps, and local roads along the city boundary, where CPD is not the responding agency, are excluded.  Additionally, while Illinois statue dictates certain criteria for reportable crashes, CPD records every reported traffic crash event, regardless of statutory thresholds.  Consequently, the dataset may encompass a broader scope of incidents compared to formal crash datasets released by the Illinois Department of Transportation.

### Stakeholders and Ethical Information

The analysis of car crash data in Chicago holds implications for a diverse array of stakeholders, each with their own interests and concerns.  These include many different groups and individuals, starting with city officials and policymakers.  These city officials, including transportation departments and policymakers, are the primary stakeholders in this analysis.  They have a vested interest in recognizing the patterns and determinants of car crashes to inform policy decisions related to road safety and traffic management.  Law enforcement agencies, including the CPD also serve as stakeholders, as they are directly involved in the collection and retention of crash data.  Relying on accurate and comprehensive data to allocate resources effectively, they focus their efforts on prioritizing enforcement and enhancing public safety.

Third, emergency response and healthcare teams concern themselves with the consequences of car crashes, specifically in terms of injuries and fatalities.  Access to accurate and effective crash data can assist with emergency preparedness and trauma care planning.  Fourth, the transportation and automotive industry as a whole serve as stakeholders, as they may utilize crash data analysis to affect product design, conduct risk assessments, and improve safety innovations.  Finally, community advocate groups represent those directly involved in and affected by car crashes, including pedestrians, cyclists, and residents of various neighborhoods.  They may push for safer streets, improved infrastructure, and more vigilant police presence. 

Assessing the ethical considerations of the data directly leads to responsible data science practice and implementation.  First, one cannot stress enough the importance of safeguarding the privacy of individuals involved in car crashes.  This includes anonymizing personally identifiable information and keeping track of data protection regulations to prevent unauthorized access or misuse of sensitive data.  Second, handling bias in data collection and interpretation goes a long way to ensure fairness and equity in the results.   This requires addressing likely biases occurring in sample selection, data collection methods, and decision-making processes.  Third, maintaining transparency in data collection methods, sources and analysis techniques fosters trust and accountability among stakeholders.  By holding the data scientists accountable with regards to assumptions and uncertainties in the results, informed decision-making and proper collaboration can occur between all parties.  Finally, upholding the ethical considerations, including social responsibilities and the adherence to legal frameworks, directs the proper use of car crash data.  By considering the ethical implications outlined above, scientists can navigate the data science concerns and provide analysis beneficial to stakeholders while promoting the safety of drivers, pedestrians, cyclists, and the community at large.

## Preparing the Data for Analysis (CODE)

```{r, echo = FALSE}
# Load packages
suppressMessages({
library(readr)
library(tidyverse)
library(MASS)
library(ISLR2)
library(leaps)
library(dplyr)
library(car)
library(ggplot2)
library(caret)
library(nnet)
library(class)
library(mapview)
library(sf)
library(data.table)
library(tree)
library(randomForest)
library(e1071)
library(glmnet)
})
```

```{r}
#Read Data
carcrashdata <- fread("https://data.cityofchicago.org/api/views/85ca-t3if/rows.csv?accessType=DOWNLOAD")
```

```{r}
# Display variables
variables <- colnames(carcrashdata)
print(variables)
```

```{r}
# Remove PII
carcrashdata <- carcrashdata %>%
  dplyr::select(-CRASH_RECORD_ID, -BEAT_OF_OCCURRENCE, -LANE_CNT)
```

```{r}
# Remove NA values from key variables
carcrashdata <- carcrashdata[complete.cases(carcrashdata$MOST_SEVERE_INJURY, carcrashdata$WEATHER_CONDITION, carcrashdata$LIGHTING_CONDITION, carcrashdata$ROADWAY_SURFACE_COND, carcrashdata$INJURIES_TOTAL, carcrashdata$INJURIES_FATAL, carcrashdata$LATITUDE, carcrashdata$LONGITUDE), ]

# Converting key variables to factors
carcrashdata <- carcrashdata %>%
  mutate(WEATHER_CONDITION = factor(WEATHER_CONDITION, levels = c("CLEAR", "SNOW", "UNKNOWN", "RAIN", "CLOUDY/OVERCAST", "FOG/SMOKE/HAZE", "BLOWING SNOW", "FREEZING RAIN/DRIZZLE", "OTHER", "SEVERE CROSS WIND GATE", "SLEET/HAIL", "BLOWING SAND, SOIL, DIRT")),
    LIGHTING_CONDITION = factor(LIGHTING_CONDITION, levels = c("DAYLIGHT", "DARKNESS, LIGHTED ROAD", "DARKNESS", "UNKNOWN", "DUSK", "DAWN")),
    ROADWAY_SURFACE_COND = factor(ROADWAY_SURFACE_COND, levels = c("DRY", "UNKNOWN","SNOW OR SLUSH","WET","OTHER","ICE","SAND, MUD, DIRT")),
    DAMAGE = factor(DAMAGE, levels = c("$500 OR LESS", "$501 - $1,500", "OVER $1,500"), ordered = TRUE))
```

```{r}
map_df(carcrashdata,~sum(is.na(.)))
```

```{r}
# Convert MOST_SEVERE_INJURY into a factor
carcrashdata$MOST_SEVERE_INJURY <- factor(carcrashdata$MOST_SEVERE_INJURY)

# Identify unique levels of MOST_SEVERE_INJURY
levels <- unique(carcrashdata$MOST_SEVERE_INJURY)
print(levels)

# Define a vector to rank the levels of MOST_SEVERE_INJURY
severity_rank <- c("NO INDICATION OF INJURY", "REPORTED, NOT EVIDENT", "NONINCAPACITATING INJURY", "INCAPACITATING INJURY", "FATAL")

# Convert levels to a factor with specified order
carcrashdata$MOST_SEVERE_INJURY <- factor(carcrashdata$MOST_SEVERE_INJURY, levels = severity_rank)

carcrashdata <- carcrashdata %>%
  mutate(MINOR_MAJOR_INJURY = case_when(
    MOST_SEVERE_INJURY %in% c("NO INDICATION OF INJURY", "REPORTED, NOT EVIDENT", "NONINCAPACITATING INJURY") ~ 0,
    MOST_SEVERE_INJURY %in% c("INCAPACITATING INJURY", "FATAL") ~ 1
  )) %>%
  filter(!is.na(MINOR_MAJOR_INJURY))
```

```{r}
injury_summary <- table(carcrashdata$MINOR_MAJOR_INJURY)

injury_summary_df <- as.data.frame(injury_summary)

colnames(injury_summary_df) <- c("Injury_Type", "Count")

injury_summary_df$Percentage <- (injury_summary_df$Count / sum(injury_summary_df$Count)) * 100

p <- ggplot(data = injury_summary_df, aes(x = "", y = Count, fill = factor(Injury_Type, labels = c("Non-Fatal", "Fatal")))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Non-Fatal vs. Fatal Injuries", fill = "Type of Injury") +
  theme_void() +
  theme(legend.position = "right")

p <- p + geom_text(aes(label = paste0(round(Percentage, 1), "%")), position = position_stack(vjust = 0.5))

p
```

```{r}
ggplot(data = carcrashdata, aes(x = factor(WEATHER_CONDITION), fill = factor(WEATHER_CONDITION))) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Accidents by Weather Condition", x = "Weather Condition", y = "Accident Count", fill = "Weather Condition")
```

### Mapping/Location

```{r}
filtered_carcrashdata <- carcrashdata %>%
  filter(!is.na(LONGITUDE), !is.na(LATITUDE), LONGITUDE != 0, LATITUDE != 0)
ggplot(filtered_carcrashdata, aes(x = LONGITUDE, y = LATITUDE, color =DAMAGE)) +
  geom_point() +
  labs(x = "Longitude", y = "Latitude", title = "Chicago Accidents by Damage")
```

Here we have an initial map of the locations of fatal injuries using latitude and longitude for the city of Chicago. However, since fatal accidents are so far outnumbered by non-fatal accidents, we don't glean much information from this plot. To indicate locations where crashes are more severe, I plotted the severity of injury. We can now see areas where costs are low and high. However, this is a challenge to pinpoint using just ggplot.

```{r}
ggplot(filtered_carcrashdata, aes(x = LONGITUDE, y = LATITUDE, color = MINOR_MAJOR_INJURY)) +
  geom_point() +
  labs(x = "Longitude", y = "Latitude", title = "Chicago Accidents by Fatalities")
```

Using the mapview package, we can isolate fatal crashes on an interactive map of Chicago.

```{r}
lethal_filtered_carcrashdata <- carcrashdata %>%
  filter(!is.na(LONGITUDE), !is.na(LATITUDE), LONGITUDE != 0, LATITUDE != 0, INJURIES_FATAL == 1)
mapview(lethal_filtered_carcrashdata, xcol = "LONGITUDE", ycol = "LATITUDE", crs = 4269, grid = FALSE) 
```

However, can we create a model to predict the location of fatal accidents? For this project, we will examine location data alongside other variables over the course of this project.

## Regression Modelling, Variable Selection (Not an Automatic Process)

```{r}
# Divide into training and testing
set.seed(123)
Y <- sample(nrow(carcrashdata), 50000)
carcrash.train <- carcrashdata[Y,]
carcrash.test <- carcrashdata[-Y,]
```

We began with simple linear regression with relevant variables. When running linear models proposing all variables, a common error message occurs: "vector memory exhausted (limit reached?)".

This is due to the sheer number of variables included in the initial selection process. We also have this error when running the same test on just training data. For this reason, we are conducting a manual variable selection process.

```{r}
Var_select_Model <- lm(MINOR_MAJOR_INJURY ~ POSTED_SPEED_LIMIT + ROADWAY_SURFACE_COND + ROAD_DEFECT + CRASH_TYPE + INTERSECTION_RELATED_I + HIT_AND_RUN_I + DAMAGE + WORK_ZONE_I + NUM_UNITS + MOST_SEVERE_INJURY + INJURIES_TOTAL + INJURIES_FATAL + INJURIES_INCAPACITATING + INJURIES_NON_INCAPACITATING + CRASH_DAY_OF_WEEK + CRASH_HOUR + CRASH_MONTH + LATITUDE + LONGITUDE, data = carcrash.train)
summary(Var_select_Model)
```

From the initial variable selection model, variables related to road conditions had more impact than defects in the road. "Hit and run" accidents are also highly correlated with injury. Additionally, date, time and geolocation had little to do with predicting injury. Next, lets drop some of the non-useful variables.

```{r}
# Injury prediction models
Roadway_Model <- lm(MINOR_MAJOR_INJURY ~ INTERSECTION_RELATED_I+ POSTED_SPEED_LIMIT+ ROADWAY_SURFACE_COND, data = carcrashdata)
summary(Roadway_Model)
```

We have a statistically significant model focusing on road conditions; however, it does not account for much variance in injuries. Next, let's try looking at some models examining different types of variables.

This model focuses on road conditions is statistically significant, it doesn't account for much variance in injuries. Let's look at some models examining different types of variables.

```{r}
# Time Model
time_model_fatal <- lm(MINOR_MAJOR_INJURY ~ CRASH_DAY_OF_WEEK + CRASH_HOUR + CRASH_MONTH, data = carcrashdata)
summary(time_model_fatal)
```

Here, we have a model related to simply the variables regarding date and time. As indicating by the dangerously low Adjusted R-squared value, little relationship exists between time and severity of injury.

```{r}
# Damage Cost Model
damage_cost_model_1 <- lm(MINOR_MAJOR_INJURY ~ INJURIES_TOTAL + DAMAGE + MOST_SEVERE_INJURY, data = carcrashdata)
summary(damage_cost_model_1)
```

Focusing on elements related to damage and injuries, our first damage cost model has an adjusted R-squared value of 1. This model suggests an astronomically high probability of over-fitting with many degrees of freedom. Let's reduce it further.

```{r}
# Damage Cost Model
damage_cost_model_2 <- lm(MINOR_MAJOR_INJURY ~ INJURIES_TOTAL + DAMAGE, data = carcrashdata)
summary(damage_cost_model_2)
```

The second model focusing on damage and number of injures is no longer over-fitting the data and has a relatively respectable adjusted R-squared value. We can do better by applying more advanced regression and classification techniques.

### Multinominal Model

```{r}
# Fit a multinomial logistic regression model
carcrash.model <- multinom(MOST_SEVERE_INJURY ~ WEATHER_CONDITION + LIGHTING_CONDITION + ROADWAY_SURFACE_COND, data = carcrash.train)
```

```{r}
# Predict probabilities for each level of injury severity in the test data
carcrash.predict <- predict(carcrash.model, newdata = carcrash.test, type = "probs")

# Calculate the average predicted probabilities for each level of injury severity
avg_probabilities <- colMeans(carcrash.predict)

# Output the average predicted probabilities
print(avg_probabilities)
```

```{r}
# Define the probabilities and categories
probabilities <- c(0.85933093, 0.04227171, 0.07947090, 0.01758836, 0.00133810)
categories <- c("NO INDICATION OF INJURY", "REPORTED, NOT EVIDENT", "NONINCAPACITATING INJURY", "INCAPACITATING INJURY", "FATAL")

# Create a data frame with categories and probabilities
data <- data.frame(categories, probabilities)

# Create the bar plot using ggplot2
ggplot(data, aes(x = categories, y = probabilities, fill = categories)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(probabilities * 100, 1), "%")), 
            position = position_stack(vjust = 0.5), 
            color = "black", 
            size = 3) + 
  scale_fill_manual(values = c("blue", "green", "orange", "red", "purple")) +
  labs(title = "Predicted Probabilities of Injury Severity",
       y = "Probabilities",
       x = "Injury Severity Category") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

This model aims to classify the severity of injuries resulting from car crashes based on several factors including weather conditions, lighting conditions, and roadway surface conditions. The summary output provides coefficients for each predictor variable, indicating their impact on the likelihood of different injury severities. For instance, certain weather conditions or poor lighting might be associated with higher probabilities of more severe injuries.

The output of predicted probabilities indicates the average probability of each injury severity category occurring in the test data. In this case, the majority of cases (86.07%) are predicted to result in "No Indication of Injury," followed by "Reported, Not Evident" (4.16%), "Nonincapacitating Injury" (7.96%), "Incapacitating Injury" (1.71%), and "Fatal" (0.10%).

This model serves as a classification model rather than a regression model because its goal is to categorize observations into discrete classes (injury severity levels) rather than predicting a continuous outcome. It uses multinomial logistic regression to model the probabilities of each category and then classifies each observation into the category with the highest probability.

### Logistic Regression Model for Predicting Fatal Accidents

```{r}
carcrashdata <- carcrashdata %>%
  mutate(FATAl_ACCIDENT = ifelse(INJURIES_FATAL > 0, 1, 0))
FATAL_Logistic <- glm(FATAl_ACCIDENT ~ CRASH_HOUR  + LIGHTING_CONDITION + POSTED_SPEED_LIMIT + FIRST_CRASH_TYPE, 
             family = binomial, data = carcrashdata)
summary(FATAL_Logistic)

# Converting FIRST_CRASH_TYPE variable to factor
unique(carcrashdata$FIRST_CRASH_TYPE)
carcrashdata <- carcrashdata %>%
  mutate(
    FIRST_CRASH_TYPE = factor(FIRST_CRASH_TYPE, levels = c("REAR END", "PARKED MOTOR VEHICLE", "PEDALCYCLIST", "PEDESTRIAN", "FIXED OBJECT","TURNING", "ANGLE", "SIDESWIPE SAME DIRECTION", "SIDESWIPE OPPOSITE DIRECTION","REAR TO SIDE", "HEAD ON", "REAR TO FRONT", "OTHER OBJECT", "ANIMAL","OTHER NONCOLLISION", "OVERTURNED", "REAR TO REAR", "TRAIN")
))
unique(carcrashdata$TRAFFICWAY_TYPE)

carcrashdata <- carcrashdata %>%
  mutate(
    TRAFFICWAY_TYPE = factor(TRAFFICWAY_TYPE, levels = c("OTHER", "DIVIDED - W/MEDIAN (NOT RAISED)", "NOT DIVIDED", "ONE-WAY","FOUR WAY", "PARKING LOT", "DIVIDED - W/MEDIAN BARRIER", "T-INTERSECTION","UNKNOWN", "RAMP", "ALLEY", "DRIVEWAY", "UNKNOWN INTERSECTION TYPE","TRAFFIC ROUTE", "FIVE POINT, OR MORE", "NOT REPORTED", "CENTER TURN LANE","L-INTERSECTION", "Y-INTERSECTION", "ROUNDABOUT")
    ))
# Filter out observations with missing values 
carcrashdata_complete <- carcrashdata[!is.na(carcrashdata$FATAl_ACCIDENT), ]

set.seed(123) 
train_index <- sample(nrow(carcrashdata_complete), 0.8 * nrow(carcrashdata_complete))  # 80% train, 20% test
train_data <- carcrashdata_complete[train_index, ]
test_data <- carcrashdata_complete[-train_index, ]

model <- glm(FATAl_ACCIDENT ~ CRASH_HOUR + LIGHTING_CONDITION + POSTED_SPEED_LIMIT + FIRST_CRASH_TYPE, 
             family = binomial, data = train_data)

predicted <- predict(model, newdata = test_data, type = "response")

predicted_class <- ifelse(predicted > 0.5, 1, 0)  
actual_class <- test_data$FATAl_ACCIDENT 

logisticmisclassification_rate <- mean(predicted_class != actual_class)
print(paste("Misclassification Rate:", logisticmisclassification_rate))
```

The logistic regression model predicts the likelihood of a fatal accident based on several factors. Variables such as CRASH_HOUR, LIGHTING_CONDITION, POSTED_SPEED_LIMIT, and FIRST_CRASH_TYPE show significant associations with the outcome. For instance, higher posted speed limits and certain crash types like pedestrian or animal involvement are associated with increased odds of a fatal accident. However, variables like FIRST_CRASH_TYPE REAR TO SIDE and FIRST_CRASH_TYPE REAR TO REAR do not appear to significantly influence the likelihood of a fatal accident. Using this model, we have a misclassification rate of 0.113%, a fantastically low value for predicting fatalities using this model.

### LDA Analysis for Posterior Probabilities - Minor vs. Major Injuries

```{r}
# Fit LDA model
lda.model <- lda(MINOR_MAJOR_INJURY ~ WEATHER_CONDITION + LIGHTING_CONDITION + ROADWAY_SURFACE_COND, data = carcrashdata)

# Summary of LDA model
summary(lda.model)

# Predict using the LDA model
predictions.lda <- predict(lda.model, newdata = carcrash.test)

# If you want the posterior probabilities of each class, you can also extract them
posterior.probs.lda <- predictions.lda$posterior
# head(posterior_probs) ####### Recommend against printing all posterior probabilities (long) unless we graph them

# Calculate average posterior probabilities for each class
posterior.class.minor <- mean(posterior.probs.lda[, "0"])
posterior.class.major <- mean(posterior.probs.lda[, "1"])

# Output the average posterior probabilities
posterior.class.minor
posterior.class.major
```

```{r}
posterior.data <- data.frame(Class = c("Minor", "Major"),
                              Probability = c(posterior.class.minor, posterior.class.major))

ggplot(posterior.data, aes(x = "", y = Probability, fill = Class)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  labs(title = "Posterior Probabilities of Minor and Major Classes",
       fill = "Class") +
  theme_void() +
  theme(legend.position = "right") +
  geom_text(aes(label = paste0(round(Probability * 100, 1), "%")),
            position = position_stack(vjust = 0.5))
```

Next, we fit a Linear Discriminant Analysis (LDA) model to measure and analyze posterior probabilities than an accident results in either a minor injury or major injury/fatality based on weather conditions, lighting conditions, and roadway surface conditions.. LDA is a classification technique used to predict the class membership of observations based on a set of predictor variables. .

In the output provided, the average posterior probability for the minor class is approximately 98.2%, indicating a high likelihood that injuries are classified as minor. Conversely, the average posterior probability for the major class is around 1.8%, suggesting a much lower likelihood of injuries being classified as major.

### Decision Tree for Predicting Injuries

```{r}
set.seed(123)
suppressWarnings(tr <- tree(as.factor(MOST_SEVERE_INJURY) ~ ., data = carcrash.train))
suppressWarnings(summary(tr))
suppressWarnings(tr)
```

```{r}
suppressWarnings(plot(tr))
suppressWarnings(text(tr))
```

```{r}
suppressWarnings(cv.tree(tr, FUN = prune.misclass))
```

```{r}
set.seed(123)
suppressWarnings({cv <- cv.tree(tr, FUN = prune.misclass)})
suppressWarnings(plot(cv))
decisiontree5missclass <- 42/50000

```

```{r}
suppressWarnings(trp <- prune.misclass(tr, best = 4))
summary(trp)
decisiontree4missclass <- 203/50000
```

```{r}
trpp <- rpart::rpart(MOST_SEVERE_INJURY ~ INJURIES_TOTAL + INJURIES_NON_INCAPACITATING + MINOR_MAJOR_INJURY, data = carcrash.train)
rpart.plot::rpart.plot(trpp)
```

```{r}
trp <- prune.misclass(tr, best = 4)
summary(trp)
```

```{r}
# Create a dataframe with probabilities
probabilities.df <- data.frame(
  Category = c("No Indication of Injury", "Reported, Not Evident", "Non-incapacitating Injury", "Incapacitating Injury", "Fatal"),
  Probability = c(0.860680, 0.041600, 0.079640, 0.017120, 0.000960)
)

probabilities.bar <- ggplot(probabilities.df, aes(x = Category, y = Probability, fill = Category)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(Probability * 100, 1), "%")), 
            vjust = -0.5, size = 3, color = "black") +
  labs(title = "Accident Severity With Decision Trees",
       fill = "Severity Category",
       x = NULL, y = NULL) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(probabilities.bar)
```

```{r}
ggplot(carcrash.train, aes(x = INJURIES_NON_INCAPACITATING, y = MOST_SEVERE_INJURY, color = MINOR_MAJOR_INJURY)) +
  geom_point() +
  labs(x = "Non-Incapacitating Injuries", y = "Severity of Injuries", title = "Injury Severity Per Decision Trees")
```

The purpose of using a classification tree like the one constructed here is to create a predictive model that can accurately classify instances into predefined categories, in this case, the severity of injuries in car crashes. The output of the tree provides insights into the relationships between predictor variables and injury severity, expressed in a hierarchical structure of decision nodes and terminal nodes. Using this classification tree, we can see that the model predicts an 86.07% chance of "No Indication of Injury," a 4.16% chance of "Reported, Not Evident", a 7.96% chance of "Non-Incapacitating Injury," a 1.71% chance of "Incapacitating Injury," and a 0.09% chance of "Fatal."\
\
After pruning, the tree has four terminal nodes, indicating the final endpoints where predictions are made. Pruning helps prevent overfitting, where the model captures noise in the training data rather than underlying patterns, by reducing complexity and improving generalizability. However, pruning may lead to a slight increase in error rates, as seen in the summary output after pruning. Because of the large probability of over-fitting by reducing the tree to four nodes, we recommend five nodes as the most optimal tree model. Overall, the classification tree serves as a valuable tool for understanding and predicting injury severity in car crashes, aiding in the development of targeted interventions and safety measures to mitigate the risk of severe injuries on the road. As indicated by our final presented graph, the best predictor of fatal injuries is the presence or lack thereof of more minor injuries. The misclassification error rate indicates the proportion of incorrectly classified instances in the training data after pruning. In this case, the misclassification error rate is 0.426%, meaning approximately 0.43% of instances are misclassified based on the pruned tree's predictions.

### Using a Decision Tree to Predict Hit-and-Run Accidents

```{r}
suppressWarnings(treehitandrun <- tree(as.factor(HIT_AND_RUN_I) ~ ., data = carcrash.train))
summary(treehitandrun)
treehitandrun
```

```{r}
plot(treehitandrun)
text(treehitandrun)
```

```{r}
suppressWarnings({cv.tree(treehitandrun, FUN = prune.misclass)})
```

While not necessarily fatal, "hit-and-run" accidents are more likely to be dangerous than other accidents. Here, we have a decision tree to predict what variables are contributing to these accidents. Running a decision tree to predict if a car crash is a "hit-and-run" can be determined by the variables related to the number of injuries and the number of responding police units. It makes sense that more police will be assigned to a "hit-and-run" crash than other accidents.

### Linear Discriminant Analysis/Variance Inflation Factor

Earlier, we built a LDA model in order to calculate posterior probabilities for establishing whether an accident would likely fall into a "minor" category (Non-Incapacitating Injuries, Non-Reported Injuries, or No Injuries) or a "major" category ("Incapacitating Injuries" or "Fatalities"). This was a relatively simple model, only relying on weather conditions, lighting conditions, and roadway surface conditions. If we try to build a more complicated LDA model, we run the likelihood of collinearity, resulting in an ineffective model.

```{r}
lda_model_1 <- lda(MINOR_MAJOR_INJURY ~ ROADWAY_SURFACE_COND + ROAD_DEFECT + CRASH_TYPE + INTERSECTION_RELATED_I + HIT_AND_RUN_I + DAMAGE + WORK_ZONE_I + NUM_UNITS + MOST_SEVERE_INJURY + INJURIES_TOTAL + INJURIES_FATAL + INJURIES_INCAPACITATING + INJURIES_NON_INCAPACITATING + CRASH_DAY_OF_WEEK + CRASH_HOUR + CRASH_MONTH + LATITUDE + LONGITUDE, data = carcrash.train) 

Predicted.fatal.lda <- predict(lda_model_1, data.frame(carcrash.test))$class

table(carcrash.test$MINOR_MAJOR_INJURY, Predicted.fatal.lda)
round(mean(carcrash.test$MINOR_MAJOR_INJURY == Predicted.fatal.lda), 3) # Classification Rate
round(mean(Predicted.fatal.lda == "Up"), 3)
round(mean(carcrash.test$MINOR_MAJOR_INJURY == "Up"), 3)
```

We are going to perform a similar "manual" variable selection methodology from earlier to construct and test a more effective LDA model.

```{r}
lda_model_2 <- lda(MINOR_MAJOR_INJURY ~ ROADWAY_SURFACE_COND + INTERSECTION_RELATED_I + HIT_AND_RUN_I + DAMAGE + NUM_UNITS + MOST_SEVERE_INJURY + INJURIES_TOTAL + INJURIES_NON_INCAPACITATING, data = carcrash.train) 

Predicted.fatal.lda2 <- predict(lda_model_2, data.frame(carcrash.test))$class

table(carcrash.test$MINOR_MAJOR_INJURY, Predicted.fatal.lda2)
round(mean(carcrash.test$MINOR_MAJOR_INJURY == Predicted.fatal.lda2), 9)
```

We have the best model possible with a correct classification rate of 99.84%. This incorporates several types of different variables to reduce the risk of multicollinearity. To test this, we will examine the Variance Inflation Factor of this model.

```{r}
# Calculate VIF
vif(lm(MINOR_MAJOR_INJURY ~ ROADWAY_SURFACE_COND + INTERSECTION_RELATED_I + HIT_AND_RUN_I + DAMAGE + NUM_UNITS + MOST_SEVERE_INJURY + INJURIES_TOTAL + INJURIES_NON_INCAPACITATING, data = carcrash.train))
```

We have strong VIF values for most variables, and respectable VIF values for most of the others. However, with a GVIF value of 13.54, "MOST_SEVERE_INJURY" is far too high to serve as an effective variable, and we should remove it from this model.

```{r}
# LDA graph
lda_model_simplified <- lda(MINOR_MAJOR_INJURY ~ NUM_UNITS + INJURIES_TOTAL, data = carcrash.train)

grid <- expand.grid(
  NUM_UNITS = seq(min(carcrash.train$NUM_UNITS), max(carcrash.train$NUM_UNITS), length.out = 100),
  INJURIES_TOTAL = seq(min(carcrash.train$INJURIES_TOTAL), max(carcrash.train$INJURIES_TOTAL), length.out = 100)
)
grid$MINOR_MAJOR_INJURY <- predict(lda_model_simplified, newdata = grid)$class
carcrash.train$predicted_class <- predict(lda_model_simplified, carcrash.train)$class

ggplot() +
  geom_tile(data = grid, aes(x = NUM_UNITS, y = INJURIES_TOTAL, fill = MINOR_MAJOR_INJURY), alpha = 0.5) +
  geom_point(data = carcrash.train, aes(x = NUM_UNITS, y = INJURIES_TOTAL, color = predicted_class)) +
  scale_fill_manual(values = c("red", "blue"), name = "Type of Injury", labels = c("Minor Injury", "Major Injury/Fatality")) +  # Change legend labels
  scale_color_manual(values = c("red", "blue"), name = "Predicted Class", labels = c("Minor Injury", "Major Injury/Fatality")) +  # Change legend labels
  labs(title = "LDA Decision Boundaries", 
       x = "Number of Units",
       y = "Total Number of Injuries")
```

Based on this decision boundary graph, we can surmise that any accidents with three or more injuries results in a major improvement in the likelihood of a fatality.

### Quadratic Discriminant Analysis

Using the same variables as our best LDA model, we also attempted to put together a Quadratic Discriminant Analysis (QDA) model.

```{r}
# qda_model_1 <- qda(MINOR_MAJOR_INJURY ~ ROADWAY_SURFACE_COND + INTERSECTION_RELATED_I + HIT_AND_RUN_I + DAMAGE + NUM_UNITS + INJURIES_TOTAL + INJURIES_NON_INCAPACITATING, data = carcrash.train) 
# 
# Predicted.fatal_qda <- predict(qda_model_1, data.frame(carcrash.test))$class
# 
# table(carcrash.test$MINOR_MAJOR_INJURY, Predicted.fatal_qda)
# QDAclass<- round(mean(carcrash.test$MINOR_MAJOR_INJURY == Predicted.fatal_qda), 9)
# QDAclass
```

```         
 Predicted.fatal_qda
         0      1
  0 725846  31526
  1   9600   4317
[1] 0.9466789
```

The above code works when run but not when rendering.

The QDA model does not perform as well as the LDA model with all other factors staying the same. We have a correct classification rate of 94.18% compared to 99.84% from the LDA model.

It would be unfeasible to graph all of the variables from the QDA model. However, we can look at the number of responding police units, as well as the number of total injuries as these have the greatest range.

```{r}
# QDA graph
qda_model_simplified <- qda(MINOR_MAJOR_INJURY ~ NUM_UNITS + INJURIES_TOTAL, data = carcrash.train)

grid <- expand.grid(
  NUM_UNITS = seq(min(carcrash.train$NUM_UNITS), max(carcrash.train$NUM_UNITS), length.out = 100),
  INJURIES_TOTAL = seq(min(carcrash.train$INJURIES_TOTAL), max(carcrash.train$INJURIES_TOTAL), length.out = 100)
)
grid$MINOR_MAJOR_INJURY <- predict(qda_model_simplified, newdata = grid)$class
carcrash.train$predicted_class <- predict(qda_model_simplified, carcrash.train)$class

ggplot() +
  geom_tile(data = grid, aes(x = NUM_UNITS, y = INJURIES_TOTAL, fill = MINOR_MAJOR_INJURY), alpha = 0.5) +
  geom_point(data = carcrash.train, aes(x = NUM_UNITS, y = INJURIES_TOTAL, color = predicted_class)) +
  scale_fill_manual(values = c("red", "blue"), name = "Severity of Injury", labels = c("Minor Injury", "Major Injury/Fatality")) +
  scale_color_manual(values = c("red", "blue"), name = "Predicted Class", labels = c("Minor Injury", "Major Injury/Fatality")) +
  labs(title = "QDA Decision Boundaries", 
       x = "Number of Units",
       y = "Total Number of Injuries")
```

\![SVM Screenshot1\](/Users/nateyoung/Documents/AU/grad/Semester_3/STAT627/Final project/QDA_Decision_Boundaries.png)

Based on these findings, we can conclude that a lower police presence along with a lower number of injuries directly correlates to a lower risk of fatality.

### KNN

We tried for many hours to perform k-Nearest Neighbors on this data set but could not get beyond this error message: "Error in knn(train = train_set, test = test_set, cl = train_labels, k = 7) : 'train' and 'class' have different lengths". This could not be fixed, even when "train" and "class" were the same length and after consulting Stack Exchange.

Don't make our mistake. Save yourself the time and headache. Don't try KNN with this data set.

### SVM

```{r}
# Divide into training and testing
set.seed(123)
Y <- sample(nrow(carcrashdata), 1000)
carcrash.train.svm <- carcrashdata[Y,]
carcrash.test.svm <- carcrashdata[-Y,]
```

```{r}
injuries.model <- lm(INJURIES_TOTAL ~ POSTED_SPEED_LIMIT + DAMAGE + CRASH_HOUR + CRASH_DAY_OF_WEEK + CRASH_MONTH, data = carcrash.train.svm)
summary(injuries.model)
```

```{r}
SVMplot1 <- carcrash.train.svm[, .(INJURIES_TOTAL, CRASH_DAY_OF_WEEK, CRASH_HOUR)]
plot(SVMplot1$CRASH_DAY_OF_WEEK, SVMplot1$CRASH_HOUR, lwd = 1, col = as.numeric(SVMplot1$INJURIES_TOTAL))
```

```{r}
# svm.model <- svm(INJURIES_TOTAL ~ ., data = carcrash.train.svm, kernel = "radial")
# 
# summary(svm.model)
# 
# predictions <- predict(svm.model, newdata = carcrash.train.svm)
# 
# svm_results <- data.frame(Actual = carcrash.train.svm$INJURIES_TOTAL, Predicted = predictions)
# 
# ggplot(svm_results, aes(x = Predicted, y = Actual)) +
#   geom_point() +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
#   labs(title = "Actual vs Predicted Values (SVM Regression)",
#        x = "Predicted Values", y = "Actual Values")
```

\`![SVM Screenshot1.](SVM_screenshot1.png)

![SVM Screenshot2.](SVM_screenshot2.png)

The above code chunk worked until rendering. I've embedded screenshots of the outputs.

We also attempted to put together a scatterplot to represent predicted values versus actual values in a support vector model.

```{r}
# MAE <- mean(abs(svm_results$Actual - svm_results$Predicted))
# 
# MSE <- mean((svm_results$Actual - svm_results$Predicted)^2)
# 
# RMSE <- sqrt(MSE)
# 
# SS_Residual <- sum((svm_results$Actual - svm_results$Predicted)^2)
# SS_Total <- sum((svm_results$Actual - mean(svm_results$Actual))^2)
# R_squared <- 1 - (SS_Residual / SS_Total)
# 
# cat("Mean Absolute Error:", MAE, "\n")
# cat("Mean Squared Error:", MSE, "\n")
# cat("Root Mean Squared Error:", RMSE, "\n")
# cat("Coefficient of Determination:", R_squared, "\n")
```

```         
Mean Absolute Error: 0.2654746 
Mean Squared Error: 0.4050351 
Root Mean Squared Error: 0.6364237 
Coefficient of Determination: 0.07016728 
```

We also attempted to put together a scatterplot to represent predicted values versus actual values in a support vector model. A low coefficient of Determination (R-squared) value of 0.0603 means that this model isn't very good at predicting the number of injuries in car crashes. But hey, at least we tried.

## Write Up/Summary

Through regression modeling, we delved into the complex web of factors influencing the financial toll of accidents, uncovering subtle relationships between variables like speed limits, weather conditions, and crash types. Simultaneously, classification techniques enabled us to predict the fatal aftermath of collisions, shedding light on crucial nuances in weather conditions and road infrastructure. We relied on LDA and QDA models, along with multinominal models, logistic regression models, decision trees, support vector models (somewhat successfully) and k-Nearest Neighbors (not at all successfully). Not all methods were successful, but each of them at least made a grand attempt at learning more about the data set and helped us to further uncover the mysteries of what contributed to the majority of crashes in the greater Chicago region.

The first significant challenge we encountered during data cleaning involved converting key variables from character to factor format. Initially, our analysis yielded numerous errors until these variables were appropriately recoded, emphasizing the importance of data preprocessing in ensuring the integrity of our analyses. Additionally, despite our efforts, KNN proved unfeasible with this dataset due to an insurmountable error, highlighting the need for flexibility and adaptation in the face of unforeseen challenges.

During the initial stages of variable selection, we strategically organized our models around distinct themes present in the data, including location-based factors, extent of damage, and environmental conditions. However, it became evident that none of these themes alone could capture the entirety of the complex dynamics at play in car crash incidents. Thus, the most effective model emerged from integrating elements across all these categories, highlighting the importance of a holistic approach in understanding and predicting the outcomes of vehicular accidents.

In our journey through the research process, the LDA model emerged as the most effective tool for predicting the severity of injuries in car crashes. By incorporating crucial variables such as road conditions, intersection details, accident costs, and injury information, this model provided valuable insights while maintaining a balance between predictive accuracy and generalizability. Our commitment to continuous learning and improvement guided us through each stage, ensuring that our approach remained rigorous and adaptable to the complexities of real-world data.

To improve future analyses, we suggest revisiting feature selection methods to ensure relevance and comprehensiveness in capturing influential variables. Additionally, experimenting with ensemble techniques or deep learning models could offer insights into complex interactions among diverse factors. Moreover, a deeper exploration of spatial analysis techniques, perhaps through geographic information system (GIS) mapping, could illuminate spatial patterns and hotspots of collisions, thereby informing targeted interventions and infrastructure improvements. In our pursuit of a safer urban transit landscape, continuous iteration and innovation remain imperative, leveraging diverse methodologies to unlock the full potential of collision data for actionable insights and societal benefit.

| Group Member  | Responsibilities                                                                                           |
|--------------|----------------------------------------------------------|
| Kevin Norris  | Introduction, LDA, Multinominal Model, Logistic Regression, SVM, Majority of writing, editing, formatting. |
| Nathan Young  | Simple Linear Regression, variable selection, Decision tree, mapping, LDA, QDA, KNN, Github, some writing. |
| Yota Sugai    | Multinomial Regression, editing, Misclassification efforts, debugging                                      |
| Murtaza Jawid | Debugging, editing, Logistic Regression, LDA, QDA, Github, some writing                                    |
